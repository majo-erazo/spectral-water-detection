# sistema_hibrido_adaptativo.py
# Sistema que elige el modelo m√°s apropiado seg√∫n tama√±o del dataset
# Mar√≠a Jos√© Erazo Gonz√°lez - UDP

import os
import pandas as pd
import numpy as np
import json
import datetime
from sklearn.model_selection import train_test_split, LeaveOneOut, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, make_scorer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb

try:
    from scipy.integrate import trapezoid as trapz
except ImportError:
    from numpy import trapz

class SistemaHibridoAdaptativo:
    """
    Sistema h√≠brido que selecciona autom√°ticamente el mejor modelo
    seg√∫n el tama√±o del dataset y tipo de contaminante
    """
    
    def __init__(self, directorio_base="todo/firmas_espectrales_csv"):
        self.directorio_base = directorio_base
        self.results_dir = "resultados_hibrido_adaptativo"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # Mapeo est√°ndar del proyecto
        self.mapeo_carpetas = {
            'Nh4_Mg_L': 'Nh4', 
            'Caffeine_Ng_L': 'Caffeine',
            'Turbidity_Ntu': 'Turbidity',
            'Doc_Mg_L': 'Doc',
            'Acesulfame_Ng_L': 'Acesulfame'
        }
        
        # Configuraci√≥n de modelos por tama√±o de dataset
        self.configuracion_modelos = {
            'extremo': {  # ‚â§ 4 muestras
                'modelo_primario': 'logistic_regression',
                'modelo_alternativo': 'svm_linear',
                'descripcion': 'Dataset extremo - Modelo lineal simple'
            },
            'pequeno': {  # 5-10 muestras
                'modelo_primario': 'random_forest',
                'modelo_alternativo': 'svm_rbf', 
                'descripcion': 'Dataset peque√±o - Ensemble simple'
            },
            'mediano': {  # 11-50 muestras
                'modelo_primario': 'xgboost_conservador',
                'modelo_alternativo': 'random_forest',
                'descripcion': 'Dataset mediano - XGBoost conservador'
            },
            'grande': {  # >50 muestras
                'modelo_primario': 'xgboost_completo',
                'modelo_alternativo': 'xgboost_conservador',
                'descripcion': 'Dataset grande - XGBoost completo'
            }
        }
    
    def determinar_categoria_dataset(self, n_muestras):
        """Determina la categor√≠a del dataset seg√∫n n√∫mero de muestras"""
        if n_muestras <= 4:
            return 'extremo'
        elif n_muestras <= 10:
            return 'pequeno'
        elif n_muestras <= 50:
            return 'mediano'
        else:
            return 'grande'
    
    def entrenar_hibrido_adaptativo(self, contaminante):
        """
        Entrenamiento h√≠brido que selecciona autom√°ticamente el mejor modelo
        """
        print(f"\n{'='*70}")
        print(f"üîÑ SISTEMA H√çBRIDO ADAPTATIVO")
        print(f"üìã Contaminante: {contaminante}")
        print(f"{'='*70}")
        
        inicio_tiempo = datetime.datetime.now()
        
        try:
            # 1. Preparar datos usando l√≥gica exitosa del diagn√≥stico
            X, y, feature_names = self.preparar_datos_optimizados(contaminante)
            
            n_muestras = len(X)
            categoria = self.determinar_categoria_dataset(n_muestras)
            config = self.configuracion_modelos[categoria]
            
            print(f"üìä Dataset: {n_muestras} muestras ‚Üí Categor√≠a: {categoria}")
            print(f"üéØ Estrategia: {config['descripcion']}")
            print(f"üîß Modelo primario: {config['modelo_primario']}")
            
            # 2. Entrenar modelo primario
            resultado_primario = self.entrenar_modelo_especifico(
                X, y, feature_names, config['modelo_primario'], contaminante
            )
            
            # 3. Si el primario falla, probar alternativo
            if not resultado_primario or resultado_primario['test_f1'] < 0.1:
                print(f"‚ö†Ô∏è Modelo primario insuficiente, probando alternativo...")
                resultado_alternativo = self.entrenar_modelo_especifico(
                    X, y, feature_names, config['modelo_alternativo'], contaminante
                )
                
                # Elegir el mejor resultado
                if resultado_alternativo and resultado_alternativo['test_f1'] > resultado_primario['test_f1']:
                    resultado_final = resultado_alternativo
                    resultado_final['modelo_usado'] = config['modelo_alternativo']
                    resultado_final['modelo_fue_alternativo'] = True
                else:
                    resultado_final = resultado_primario
                    resultado_final['modelo_usado'] = config['modelo_primario']
                    resultado_final['modelo_fue_alternativo'] = False
            else:
                resultado_final = resultado_primario
                resultado_final['modelo_usado'] = config['modelo_primario']
                resultado_final['modelo_fue_alternativo'] = False
            
            # 4. Agregar metadatos
            fin_tiempo = datetime.datetime.now()
            tiempo_total = (fin_tiempo - inicio_tiempo).total_seconds()
            
            resultado_final.update({
                'contaminante': contaminante,
                'metodo': 'sistema_hibrido_adaptativo',
                'categoria_dataset': categoria,
                'n_muestras_total': n_muestras,
                'tiempo_entrenamiento': tiempo_total,
                'features_utilizados': feature_names,
                'estrategia_usada': config['descripcion']
            })
            
            # 5. Mostrar y guardar resultados
            self._mostrar_resultados_hibridos(resultado_final)
            self._guardar_resultados_hibridos(contaminante, resultado_final)
            
            return resultado_final
            
        except Exception as e:
            print(f"‚ùå Error en sistema h√≠brido: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def preparar_datos_optimizados(self, contaminante):
        """
        Prepara datos usando la l√≥gica exitosa del diagn√≥stico
        """
        print(f"üìä Preparando datos optimizados para {contaminante}...")
        
        # 1. Cargar datos crudos (misma l√≥gica que diagn√≥stico exitoso)
        datos_espectrales = self.cargar_datos_crudos(contaminante)
        
        # 2. Extraer features (misma l√≥gica que diagn√≥stico exitoso)  
        features = self.extraer_features_robustos(datos_espectrales)
        
        # 3. Crear dataset (misma l√≥gica que diagn√≥stico exitoso)
        dataset = self.crear_dataset_robusto(features)
        
        # 4. Preparar para entrenamiento
        feature_columns = [col for col in dataset.columns if col != 'label']
        X = dataset[feature_columns].values
        y = dataset['label'].values
        
        print(f"   ‚úÖ Dataset preparado: {X.shape}, Features: {len(feature_columns)}")
        
        return X, y, feature_columns
    
    def cargar_datos_crudos(self, contaminante):
        """Carga datos crudos (misma l√≥gica exitosa del diagn√≥stico)"""
        carpeta = self.mapeo_carpetas[contaminante]
        ruta_carpeta = os.path.join(self.directorio_base, carpeta)
        
        archivos_espectrales = [f for f in os.listdir(ruta_carpeta) 
                              if f.endswith('_datos_espectrales.csv')]
        archivo_espectral = archivos_espectrales[0]
        ruta_archivo = os.path.join(ruta_carpeta, archivo_espectral)
        
        datos = pd.read_csv(ruta_archivo)
        datos = datos.dropna().sort_values('wavelength').reset_index(drop=True)
        
        return datos
    
    def extraer_features_robustos(self, datos):
        """Extrae features robustos (misma l√≥gica exitosa del diagn√≥stico)"""
        
        wavelengths = datos['wavelength'].values
        high_response = datos['high_mean'].values
        low_response = datos['low_mean'].values
        
        features = {}
        
        # Features estad√≠sticos b√°sicos (que funcionaron en diagn√≥stico)
        for concentracion, response in [('high', high_response), ('low', low_response)]:
            features[f'{concentracion}_mean'] = np.mean(response)
            features[f'{concentracion}_std'] = np.std(response)
            features[f'{concentracion}_max'] = np.max(response)
            features[f'{concentracion}_min'] = np.min(response)
            features[f'{concentracion}_range'] = np.ptp(response)
            features[f'{concentracion}_auc'] = trapz(response, wavelengths)
            
            if len(wavelengths) > 1:
                slope, _ = np.polyfit(wavelengths, response, 1)
                features[f'{concentracion}_slope'] = slope
        
        # Features comparativos (los m√°s discriminativos seg√∫n diagn√≥stico)
        features['ratio_mean'] = features['high_mean'] / (features['low_mean'] + 1e-8)
        features['diff_mean'] = features['high_mean'] - features['low_mean']
        features['ratio_auc'] = features['high_auc'] / (features['low_auc'] + 1e-8)
        features['ratio_max'] = features['high_max'] / (features['low_max'] + 1e-8)
        
        return features
    
    def crear_dataset_robusto(self, features):
        """Crea dataset robusto (misma l√≥gica exitosa del diagn√≥stico)"""
        
        # Muestra alta concentraci√≥n (original)
        muestra_alta = list(features.values())
        
        # Muestra baja concentraci√≥n (invertida - l√≥gica que funcion√≥)
        muestra_baja = []
        for nombre, valor in features.items():
            if nombre.startswith('high_'):
                low_nombre = nombre.replace('high_', 'low_')
                if low_nombre in features:
                    muestra_baja.append(features[low_nombre])
                else:
                    muestra_baja.append(valor * 0.5)
            elif nombre.startswith('low_'):
                high_nombre = nombre.replace('low_', 'high_')
                if high_nombre in features:
                    muestra_baja.append(features[high_nombre])
                else:
                    muestra_baja.append(valor * 1.5)
            elif 'ratio' in nombre:
                muestra_baja.append(1 / (valor + 1e-8))
            elif 'diff' in nombre:
                muestra_baja.append(-valor)
            else:
                muestra_baja.append(valor)
        
        # Agregar algunas muestras con variabilidad controlada
        samples = [muestra_alta, muestra_baja]
        labels = [1, 0]
        
        # Agregar 2-4 muestras adicionales con noise conservador
        for i in range(2):
            # Alta concentraci√≥n con noise
            noise_alta = [val * np.random.normal(1.0, 0.1) for val in muestra_alta]
            samples.append(noise_alta)
            labels.append(1)
            
            # Baja concentraci√≥n con noise
            noise_baja = [val * np.random.normal(1.0, 0.1) for val in muestra_baja]
            samples.append(noise_baja)
            labels.append(0)
        
        # Crear DataFrame
        feature_names = list(features.keys())
        df = pd.DataFrame(samples, columns=feature_names)
        df['label'] = labels
        
        return df
    
    def entrenar_modelo_especifico(self, X, y, feature_names, tipo_modelo, contaminante):
        """
        Entrena un modelo espec√≠fico seg√∫n el tipo
        """
        print(f"üîß Entrenando modelo: {tipo_modelo}")
        
        try:
            # Escalado de datos
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # Divisi√≥n train/test (si hay suficientes datos)
            if len(X) >= 4:
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=0.3, random_state=42, stratify=y
                )
            else:
                # Para datasets extremos, train=test
                X_train = X_test = X_scaled
                y_train = y_test = y
            
            # Crear y entrenar modelo seg√∫n tipo
            if tipo_modelo == 'logistic_regression':
                modelo = LogisticRegression(random_state=42, max_iter=1000, C=0.1)
                
            elif tipo_modelo == 'svm_linear':
                modelo = SVC(kernel='linear', random_state=42, C=0.1, probability=True)
                
            elif tipo_modelo == 'svm_rbf':
                modelo = SVC(kernel='rbf', random_state=42, C=1.0, gamma='scale', probability=True)
                
            elif tipo_modelo == 'random_forest':
                modelo = RandomForestClassifier(
                    n_estimators=10, max_depth=3, random_state=42,
                    min_samples_split=2, min_samples_leaf=1
                )
                
            elif tipo_modelo == 'xgboost_conservador':
                modelo = xgb.XGBClassifier(
                    n_estimators=5, max_depth=2, learning_rate=0.1,
                    reg_alpha=1.0, reg_lambda=2.0, random_state=42, verbosity=0
                )
                
            elif tipo_modelo == 'xgboost_completo':
                modelo = xgb.XGBClassifier(
                    n_estimators=20, max_depth=4, learning_rate=0.05,
                    reg_alpha=0.5, reg_lambda=1.0, random_state=42, verbosity=0
                )
            
            # Entrenar modelo
            modelo.fit(X_train, y_train)
            
            # Predicciones
            y_train_pred = modelo.predict(X_train)
            y_test_pred = modelo.predict(X_test)
            
            # M√©tricas
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            train_f1 = f1_score(y_train, y_train_pred, zero_division=0)
            test_f1 = f1_score(y_test, y_test_pred, zero_division=0)
            
            # AUC si es posible
            try:
                if hasattr(modelo, 'predict_proba'):
                    y_test_proba = modelo.predict_proba(X_test)[:, 1]
                    if len(set(y_test)) > 1:
                        auc = roc_auc_score(y_test, y_test_proba)
                    else:
                        auc = 0.5
                else:
                    auc = 0.5
            except:
                auc = 0.5
            
            # Feature importance si est√° disponible
            feature_importance = {}
            if hasattr(modelo, 'feature_importances_'):
                for i, imp in enumerate(modelo.feature_importances_):
                    if i < len(feature_names):
                        feature_importance[feature_names[i]] = float(imp)
            elif hasattr(modelo, 'coef_'):
                coef = modelo.coef_[0] if len(modelo.coef_.shape) > 1 else modelo.coef_
                for i, imp in enumerate(np.abs(coef)):
                    if i < len(feature_names):
                        feature_importance[feature_names[i]] = float(imp)
            
            # Diagn√≥stico de overfitting
            gap_f1 = train_f1 - test_f1
            gap_acc = train_acc - test_acc
            
            if gap_f1 > 0.2:
                diagnostico = "OVERFITTING_SEVERO"
            elif gap_f1 > 0.1:
                diagnostico = "OVERFITTING_MODERADO"
            elif gap_f1 > 0.05:
                diagnostico = "LEVE_OVERFITTING"
            else:
                diagnostico = "ROBUSTO"
            
            resultado = {
                'tipo_modelo': tipo_modelo,
                'test_accuracy': float(test_acc),
                'test_f1': float(test_f1),
                'train_accuracy': float(train_acc),
                'train_f1': float(train_f1),
                'gap_accuracy': float(gap_acc),
                'gap_f1': float(gap_f1),
                'auc': float(auc),
                'diagnostico_overfitting': diagnostico,
                'feature_importance': feature_importance,
                'n_muestras_train': len(X_train),
                'n_muestras_test': len(X_test),
                'exito': True
            }
            
            print(f"   ‚úÖ {tipo_modelo}: F1={test_f1:.3f}, Acc={test_acc:.3f}, Gap={gap_f1:+.3f}")
            
            return resultado
            
        except Exception as e:
            print(f"   ‚ùå Error en {tipo_modelo}: {str(e)}")
            return {'tipo_modelo': tipo_modelo, 'test_f1': 0.0, 'exito': False, 'error': str(e)}
    
    def _mostrar_resultados_hibridos(self, resultado):
        """Muestra resultados del sistema h√≠brido"""
        
        print(f"\n{'='*70}")
        print(f"üîÑ RESULTADOS SISTEMA H√çBRIDO")
        print(f"{'='*70}")
        
        print(f"üìã Contaminante: {resultado['contaminante']}")
        print(f"üìä Categor√≠a dataset: {resultado['categoria_dataset']} ({resultado['n_muestras_total']} muestras)")
        print(f"üîß Modelo usado: {resultado['modelo_usado']}")
        print(f"üéØ Estrategia: {resultado['estrategia_usada']}")
        
        if resultado.get('modelo_fue_alternativo'):
            print(f"‚ö†Ô∏è Se us√≥ modelo alternativo (primario insuficiente)")
        
        print(f"\nüìä M√âTRICAS FINALES:")
        print(f"   üéØ Test F1:       {resultado['test_f1']:.4f}")
        print(f"   üéØ Test Accuracy: {resultado['test_accuracy']:.4f}")
        print(f"   üéØ AUC:           {resultado['auc']:.4f}")
        
        print(f"\nüîç DIAGN√ìSTICO:")
        diagnostico = resultado['diagnostico_overfitting']
        gap_f1 = resultado['gap_f1']
        
        emoji_diag = {
            'ROBUSTO': '‚úÖ',
            'LEVE_OVERFITTING': 'üíõ',
            'OVERFITTING_MODERADO': '‚ö†Ô∏è', 
            'OVERFITTING_SEVERO': 'üö®'
        }.get(diagnostico, '‚ùì')
        
        print(f"   {emoji_diag} Estado: {diagnostico}")
        print(f"   üìä Gap F1: {gap_f1:+.4f}")
        
        # Evaluaci√≥n del resultado
        f1 = resultado['test_f1']
        if f1 >= 0.8:
            evaluacion = "üü¢ EXCELENTE"
        elif f1 >= 0.6:
            evaluacion = "üü° BUENO"
        elif f1 >= 0.4:
            evaluacion = "üü† MODERADO"
        elif f1 > 0.1:
            evaluacion = "üî¥ BAJO"
        else:
            evaluacion = "‚ö´ FALLO"
        
        print(f"   üèÜ Evaluaci√≥n: {evaluacion}")
        
        # Top features si est√°n disponibles
        if resultado['feature_importance']:
            print(f"\nüîë TOP FEATURES:")
            top_features = sorted(resultado['feature_importance'].items(), 
                                key=lambda x: x[1], reverse=True)[:5]
            for i, (feature, importance) in enumerate(top_features, 1):
                print(f"   {i}. {feature}: {importance:.4f}")
        
        print(f"\n‚è±Ô∏è Tiempo: {resultado['tiempo_entrenamiento']:.1f}s")
    
    def _guardar_resultados_hibridos(self, contaminante, resultado):
        """Guarda resultados del sistema h√≠brido"""
        try:
            dir_contaminante = os.path.join(self.results_dir, contaminante)
            os.makedirs(dir_contaminante, exist_ok=True)
            
            ruta_json = os.path.join(dir_contaminante, f"{contaminante}_hibrido.json")
            
            with open(ruta_json, 'w', encoding='utf-8') as f:
                json.dump(resultado, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"   üíæ Resultados guardados: {ruta_json}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error guardando: {e}")

def probar_sistema_hibrido():
    """Prueba el sistema h√≠brido con los contaminantes de diagn√≥stico"""
    
    print("üîÑ PRUEBA SISTEMA H√çBRIDO ADAPTATIVO")
    print("="*50)
    print("üéØ Usando datos exitosos del diagn√≥stico")
    print()
    
    sistema = SistemaHibridoAdaptativo("todo/firmas_espectrales_csv")
    
    contaminantes_test = ['Nh4_Mg_L', 'Caffeine_Ng_L', 'Turbidity_Ntu']
    resultados = {}
    
    for i, contaminante in enumerate(contaminantes_test, 1):
        print(f"\n[{i}/3] üî¨ PROCESANDO: {contaminante}")
        
        resultado = sistema.entrenar_hibrido_adaptativo(contaminante)
        
        if resultado:
            resultados[contaminante] = resultado
            
            # Mostrar resultado inmediato
            f1 = resultado['test_f1']
            modelo = resultado['modelo_usado']
            categoria = resultado['categoria_dataset']
            
            if f1 >= 0.6:
                emoji = "‚úÖ"
                estado = "√âXITO"
            elif f1 >= 0.3:
                emoji = "üíõ"
                estado = "PARCIAL"
            else:
                emoji = "üö®"
                estado = "FALLO"
            
            print(f"      {emoji} RESULTADO: F1={f1:.3f} | Modelo={modelo} | Cat={categoria} | {estado}")
    
    # Resumen final
    print(f"\n{'='*60}")
    print(f"üìä RESUMEN SISTEMA H√çBRIDO")
    print(f"{'='*60}")
    
    if resultados:
        print(f"‚úÖ Resultados: {len(resultados)}/3")
        print()
        print(f"{'Contaminante':<15} | {'F1':<6} | {'Modelo':<12} | {'Categor√≠a':<8}")
        print("-" * 50)
        
        f1_scores = []
        for cont, res in resultados.items():
            f1 = res['test_f1']
            modelo = res['modelo_usado'][:10]
            categoria = res['categoria_dataset']
            
            f1_scores.append(f1)
            
            if f1 >= 0.6:
                estado = "üü¢"
            elif f1 >= 0.3:
                estado = "üü°"
            else:
                estado = "üî¥"
            
            print(f"{cont:<15} | {f1:<6.3f} | {modelo:<12} | {categoria:<8} {estado}")
        
        print()
        print(f"üìä F1 promedio: {np.mean(f1_scores):.3f}")
        
        # Verificar mejora vs sistema anterior
        exitos = sum(1 for f1 in f1_scores if f1 >= 0.6)
        print(f"üéØ Casos exitosos: {exitos}/3")
        
        if exitos >= 2:
            print(f"üéâ SISTEMA H√çBRIDO EXITOSO!")
        elif exitos >= 1:
            print(f"üíõ SISTEMA H√çBRIDO PARCIALMENTE EXITOSO")
        else:
            print(f"üî¥ SISTEMA H√çBRIDO NECESITA AJUSTES")
    
    return resultados

if __name__ == "__main__":
    import numpy as np
    probar_sistema_hibrido()