import os
import pandas as pd
import numpy as np
import json
import datetime
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb
from scipy import signal

try:
    from scipy.integrate import trapezoid as trapz
except ImportError:
    from numpy import trapz

class SistemaCompletoQuimicoHibrido:
    """
    Sistema final que combina:
    1. Adaptaci√≥n espec√≠fica por tipo qu√≠mico de contaminante
    2. Selecci√≥n h√≠brida de modelos seg√∫n tama√±o de dataset
    3. Features qu√≠micamente relevantes
    4. Validaci√≥n robusta
    """
    
    def __init__(self, directorio_base="todo/firmas_espectrales_csv"):
        self.directorio_base = directorio_base
        self.results_dir = "resultados_sistema_completo"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # Mapeo completo de contaminantes
        self.mapeo_carpetas = {
            'Doc_Mg_L': 'Doc',
            'Nh4_Mg_L': 'Nh4', 
            'Turbidity_Ntu': 'Turbidity',
            'Caffeine_Ng_L': 'Caffeine',
            'Acesulfame_Ng_L': 'Acesulfame',
            '4-&5-Methylbenzotriazole_Ng_L': 'Methylbenzotriazole',
            '6Ppd-Quinone_Ng_L': 'Quinone',
            '13-Diphenylguanidine_Ng_L': 'Diphenylguanidine',
            'Benzotriazole_Ng_L': 'Benzotriazole',
            'Candesartan_Ng_L': 'Candesartan',
            'Citalopram_Ng_L': 'Citalopram',
            'Cyclamate_Ng_L': 'Cyclamate',
            'Deet_Ng_L': 'Deet',
            'Diclofenac_Ng_L': 'Diclofenac',
            'Diuron_Ng_L': 'Diuron',
            'Hmmm_Ng_L': 'Hmmm',
            'Hydrochlorthiazide_Ng_L': 'Hydrochlorthiazide',
            'Mecoprop_Ng_L': 'Mecoprop',
            'Nsol_Mg_L': 'Nsol',
            'Oit_Ng_L': 'Oit',
            'Po4_Mg_L': 'Po4',
            'So4_Mg_L': 'So4'
        }
        
        # Perfiles qu√≠micos espec√≠ficos (expandidos)
        self.perfiles_quimicos = self._inicializar_perfiles_expandidos()
        
        # Configuraci√≥n h√≠brida de modelos seg√∫n tama√±o
        self.config_hibrida = {
            'extremo': {  # 2-4 muestras
                'modelos': ['logistic_regression', 'svm_linear'],
                'descripcion': 'Modelos lineales simples'
            },
            'pequeno': {  # 5-10 muestras  
                'modelos': ['random_forest', 'svm_rbf'],
                'descripcion': 'Ensembles robustos'
            },
            'mediano': {  # 11-30 muestras
                'modelos': ['random_forest', 'xgboost_conservador'],
                'descripcion': 'Ensembles + XGBoost conservador'
            },
            'grande': {  # >30 muestras
                'modelos': ['xgboost_completo', 'random_forest'],
                'descripcion': 'XGBoost completo + fallback'
            }
        }
    
    def _inicializar_perfiles_expandidos(self):
        """Perfiles qu√≠micos expandidos para todos los contaminantes"""
        return {
            # INORG√ÅNICOS - Iones simples
            'Nh4_Mg_L': {
                'tipo': 'inorganico', 'subtipo': 'ion_amonio',
                'regiones_criticas': [(200, 280)],
                'features_especificos': ['uv_absorption', 'slope_uv'],
                'complejidad_esperada': 'baja',
                'separabilidad_esperada': 'alta'
            },
            'Po4_Mg_L': {
                'tipo': 'inorganico', 'subtipo': 'ion_fosfato',
                'regiones_criticas': [(200, 250)],
                'features_especificos': ['uv_extreme', 'sharp_absorption'],
                'complejidad_esperada': 'baja',
                'separabilidad_esperada': 'alta'
            },
            'So4_Mg_L': {
                'tipo': 'inorganico', 'subtipo': 'ion_sulfato',
                'regiones_criticas': [(200, 300)],
                'features_especificos': ['broad_uv', 'moderate_absorption'],
                'complejidad_esperada': 'baja',
                'separabilidad_esperada': 'media'
            },
            
            # ORG√ÅNICOS SIMPLES - Compuestos con crom√≥foros espec√≠ficos
            'Caffeine_Ng_L': {
                'tipo': 'organico', 'subtipo': 'xantina_alcaloide',
                'regiones_criticas': [(250, 300), (350, 400)],
                'features_especificos': ['dual_peaks', 'chromophore_analysis'],
                'complejidad_esperada': 'media',
                'separabilidad_esperada': 'alta'
            },
            'Acesulfame_Ng_L': {
                'tipo': 'organico', 'subtipo': 'edulcorante_artificial',
                'regiones_criticas': [(220, 280)],
                'features_especificos': ['uv_signature', 'specific_absorption'],
                'complejidad_esperada': 'media',
                'separabilidad_esperada': 'media'
            },
            
            # FARMAC√âUTICOS - Estructuras complejas
            'Candesartan_Ng_L': {
                'tipo': 'organico', 'subtipo': 'farmaceutico_complejo',
                'regiones_criticas': [(250, 350), (400, 500)],
                'features_especificos': ['multi_peak', 'complex_structure'],
                'complejidad_esperada': 'alta',
                'separabilidad_esperada': 'media'
            },
            'Diclofenac_Ng_L': {
                'tipo': 'organico', 'subtipo': 'antiinflamatorio',
                'regiones_criticas': [(275, 285), (320, 330)],
                'features_especificos': ['precise_peaks', 'narrow_bands'],
                'complejidad_esperada': 'media',
                'separabilidad_esperada': 'alta'
            },
            
            # PAR√ÅMETROS F√çSICO-QU√çMICOS
            'Turbidity_Ntu': {
                'tipo': 'fisicoquimico', 'subtipo': 'dispersion_particulas',
                'regiones_criticas': [(400, 800)],
                'features_especificos': ['broadband_scattering', 'uniform_response'],
                'complejidad_esperada': 'alta',
                'separabilidad_esperada': 'muy_alta'
            },
            'Doc_Mg_L': {
                'tipo': 'fisicoquimico', 'subtipo': 'carbono_organico_disuelto',
                'regiones_criticas': [(200, 400), (450, 600)],
                'features_especificos': ['broad_organic', 'multiple_chromophores'],
                'complejidad_esperada': 'muy_alta',
                'separabilidad_esperada': 'media'
            }
        }
    
    def entrenar_contaminante_completo(self, contaminante):
        """
        Entrenamiento completo adaptado qu√≠mica y t√©cnicamente
        """
        print(f"\n{'='*70}")
        print(f"üß¨ SISTEMA COMPLETO: QU√çMICO + H√çBRIDO")
        print(f"üìã Contaminante: {contaminante}")
        print(f"{'='*70}")
        
        inicio_tiempo = datetime.datetime.now()
        
        try:
            # 1. Determinar perfil qu√≠mico
            perfil = self.perfiles_quimicos.get(contaminante)
            if perfil:
                print(f"üè∑Ô∏è Tipo: {perfil['tipo']} - {perfil['subtipo']}")
                print(f"üåà Regiones cr√≠ticas: {perfil['regiones_criticas']}")
                print(f"üéØ Complejidad esperada: {perfil['complejidad_esperada']}")
                print(f"üìä Separabilidad esperada: {perfil['separabilidad_esperada']}")
            else:
                print(f"‚ö†Ô∏è Perfil no catalogado - usando configuraci√≥n gen√©rica")
                perfil = {'tipo': 'desconocido', 'subtipo': 'generico'}
            
            # 2. Preparar datos con features qu√≠micamente espec√≠ficos
            X, y, feature_names = self.preparar_datos_quimico_especificos(contaminante, perfil)
            
            # 3. Determinar estrategia h√≠brida
            n_muestras = len(X)
            categoria_dataset = self.determinar_categoria_dataset(n_muestras)
            modelos_a_probar = self.config_hibrida[categoria_dataset]['modelos']
            
            print(f"üìä Dataset: {n_muestras} muestras ‚Üí Categor√≠a: {categoria_dataset}")
            print(f"üîß Modelos a probar: {modelos_a_probar}")
            
            # 4. Entrenar m√∫ltiples modelos y elegir el mejor
            mejor_resultado = None
            mejor_f1 = -1
            
            for modelo_tipo in modelos_a_probar:
                print(f"\nüîß Probando modelo: {modelo_tipo}")
                
                resultado = self.entrenar_modelo_quimico_especifico(
                    X, y, feature_names, modelo_tipo, contaminante, perfil
                )
                
                if resultado and resultado['test_f1'] > mejor_f1:
                    mejor_f1 = resultado['test_f1']
                    mejor_resultado = resultado
                    mejor_resultado['modelo_usado'] = modelo_tipo
            
            # 5. Finalizar resultado
            if mejor_resultado:
                fin_tiempo = datetime.datetime.now()
                tiempo_total = (fin_tiempo - inicio_tiempo).total_seconds()
                
                mejor_resultado.update({
                    'contaminante': contaminante,
                    'metodo': 'sistema_completo_quimico_hibrido',
                    'perfil_quimico': perfil,
                    'categoria_dataset': categoria_dataset,
                    'n_muestras_total': n_muestras,
                    'tiempo_entrenamiento': tiempo_total,
                    'features_utilizados': feature_names,
                    'modelos_probados': modelos_a_probar
                })
                
                # 6. Mostrar y guardar resultados
                self._mostrar_resultados_completos(mejor_resultado)
                self._guardar_resultados_completos(contaminante, mejor_resultado)
                
                return mejor_resultado
            else:
                print(f"‚ùå Ning√∫n modelo funcion√≥ adecuadamente")
                return None
            
        except Exception as e:
            print(f"‚ùå Error en sistema completo: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def preparar_datos_quimico_especificos(self, contaminante, perfil):
        """
        Prepara datos con features qu√≠micamente espec√≠ficos seg√∫n el perfil
        """
        print(f"üî¨ Preparando datos qu√≠micamente espec√≠ficos...")
        
        # 1. Cargar datos crudos (l√≥gica exitosa probada)
        datos_espectrales = self.cargar_datos_crudos(contaminante)
        
        # 2. Extraer features espec√≠ficos seg√∫n qu√≠mica
        features = self.extraer_features_quimico_especificos(datos_espectrales, perfil)
        
        # 3. Crear dataset con strategy qu√≠mica espec√≠fica
        dataset = self.crear_dataset_quimico_adaptativo(features, perfil)
        
        # 4. Preparar matrices
        feature_columns = [col for col in dataset.columns if col != 'label']
        X = dataset[feature_columns].values
        y = dataset['label'].values
        
        print(f"   ‚úÖ Dataset qu√≠mico-espec√≠fico: {X.shape}, Features: {len(feature_columns)}")
        
        return X, y, feature_columns
    
    def extraer_features_quimico_especificos(self, datos, perfil):
        """
        Extrae features espec√≠ficos seg√∫n el perfil qu√≠mico del contaminante
        """
        wavelengths = datos['wavelength'].values
        high_response = datos['high_mean'].values
        low_response = datos['low_mean'].values
        
        features = {}
        
        # Features b√°sicos universales (probados exitosos)
        for conc, response in [('high', high_response), ('low', low_response)]:
            features[f'{conc}_mean'] = np.mean(response)
            features[f'{conc}_std'] = np.std(response)
            features[f'{conc}_max'] = np.max(response)
            features[f'{conc}_min'] = np.min(response)
            features[f'{conc}_auc'] = trapz(response, wavelengths)
            
            if len(wavelengths) > 1:
                slope, _ = np.polyfit(wavelengths, response, 1)
                features[f'{conc}_slope'] = slope
        
        # Features qu√≠micamente espec√≠ficos seg√∫n tipo
        if perfil['tipo'] == 'inorganico':
            features.update(self._features_inorganicos_especificos(wavelengths, high_response, low_response, perfil))
        elif perfil['tipo'] == 'organico':
            features.update(self._features_organicos_especificos(wavelengths, high_response, low_response, perfil))
        elif perfil['tipo'] == 'fisicoquimico':
            features.update(self._features_fisicoquimicos_especificos(wavelengths, high_response, low_response, perfil))
        
        # Features de regiones cr√≠ticas espec√≠ficas
        for i, (start, end) in enumerate(perfil.get('regiones_criticas', [])):
            mask = (wavelengths >= start) & (wavelengths <= end)
            if np.any(mask):
                region_name = f"region_{i}"
                features[f'{region_name}_high_mean'] = np.mean(high_response[mask])
                features[f'{region_name}_low_mean'] = np.mean(low_response[mask])
                features[f'{region_name}_ratio'] = features[f'{region_name}_high_mean'] / (features[f'{region_name}_low_mean'] + 1e-8)
                features[f'{region_name}_auc'] = trapz(high_response[mask], wavelengths[mask])
        
        # Features comparativos (los m√°s exitosos seg√∫n diagn√≥stico)
        features['ratio_mean'] = features['high_mean'] / (features['low_mean'] + 1e-8)
        features['diff_mean'] = features['high_mean'] - features['low_mean']
        features['ratio_auc'] = features['high_auc'] / (features['low_auc'] + 1e-8)
        features['ratio_max'] = features['high_max'] / (features['low_max'] + 1e-8)
        
        return features
    
    def _features_inorganicos_especificos(self, wavelengths, high_response, low_response, perfil):
        """Features espec√≠ficos para iones inorg√°nicos"""
        features = {}
        
        # Iones absorben fuertemente en UV
        uv_mask = wavelengths <= 300
        if np.any(uv_mask):
            features['ion_uv_high'] = np.mean(high_response[uv_mask])
            features['ion_uv_low'] = np.mean(low_response[uv_mask])
            features['ion_uv_enhancement'] = features['ion_uv_high'] / (features['ion_uv_low'] + 1e-8)
            
            # Pendiente UV caracter√≠stica
            if np.sum(uv_mask) > 2:
                uv_slope, _ = np.polyfit(wavelengths[uv_mask], high_response[uv_mask], 1)
                features['ion_uv_slope'] = uv_slope
        
        return features
    
    def _features_organicos_especificos(self, wavelengths, high_response, low_response, perfil):
        """Features espec√≠ficos para compuestos org√°nicos"""
        features = {}
        
        # An√°lisis de picos (importante para org√°nicos)
        peaks_high, _ = signal.find_peaks(high_response, height=np.percentile(high_response, 60))
        peaks_low, _ = signal.find_peaks(low_response, height=np.percentile(low_response, 60))
        
        features['organic_peaks_high'] = len(peaks_high)
        features['organic_peaks_low'] = len(peaks_low)
        features['organic_peak_enhancement'] = features['organic_peaks_high'] - features['organic_peaks_low']
        
        # Crom√≥foros en UV-visible
        chromophore_mask = (wavelengths >= 250) & (wavelengths <= 400)
        if np.any(chromophore_mask):
            features['chromophore_auc_high'] = trapz(high_response[chromophore_mask], wavelengths[chromophore_mask])
            features['chromophore_auc_low'] = trapz(low_response[chromophore_mask], wavelengths[chromophore_mask])
            features['chromophore_enhancement'] = features['chromophore_auc_high'] / (features['chromophore_auc_low'] + 1e-8)
        
        return features
    
    def _features_fisicoquimicos_especificos(self, wavelengths, high_response, low_response, perfil):
        """Features espec√≠ficos para par√°metros f√≠sico-qu√≠micos"""
        features = {}
        
        # Dispersi√≥n para turbidez
        if 'turbidity' in perfil['subtipo'].lower():
            visible_mask = (wavelengths >= 400) & (wavelengths <= 700)
            if np.any(visible_mask):
                # Uniformidad de dispersi√≥n
                features['scattering_uniformity_high'] = np.std(high_response[visible_mask])
                features['scattering_uniformity_low'] = np.std(low_response[visible_mask])
                features['scattering_enhancement'] = features['scattering_uniformity_high'] / (features['scattering_uniformity_low'] + 1e-8)
        
        # M√∫ltiples crom√≥foros para DOC
        elif 'carbono' in perfil['subtipo'].lower():
            for band_start, band_end, band_name in [(200, 300, 'uv'), (300, 400, 'uv_vis'), (400, 500, 'vis')]:
                band_mask = (wavelengths >= band_start) & (wavelengths <= band_end)
                if np.any(band_mask):
                    features[f'doc_{band_name}_high'] = trapz(high_response[band_mask], wavelengths[band_mask])
                    features[f'doc_{band_name}_low'] = trapz(low_response[band_mask], wavelengths[band_mask])
        
        return features
    
    def crear_dataset_quimico_adaptativo(self, features, perfil):
        """
        Crea dataset adaptado seg√∫n complejidad qu√≠mica esperada
        """
        separabilidad = perfil.get('separabilidad_esperada', 'media')
        
        # N√∫mero de muestras seg√∫n separabilidad esperada
        if separabilidad == 'muy_alta':
            n_samples = 2  # Datos perfectamente separables
        elif separabilidad == 'alta':
            n_samples = 3  # Algunas muestras adicionales
        elif separabilidad == 'media':
            n_samples = 4  # M√°s muestras para casos dif√≠ciles
        else:
            n_samples = 5  # Casos m√°s complejos
        
        print(f"   üéØ Separabilidad esperada: {separabilidad} ‚Üí {n_samples*2} muestras")
        
        # Crear muestras usando l√≥gica exitosa probada
        muestra_alta = list(features.values())
        muestra_baja = []
        
        for nombre, valor in features.items():
            if nombre.startswith('high_'):
                low_nombre = nombre.replace('high_', 'low_')
                if low_nombre in features:
                    muestra_baja.append(features[low_nombre])
                else:
                    muestra_baja.append(valor * 0.5)
            elif nombre.startswith('low_'):
                high_nombre = nombre.replace('low_', 'high_')
                if high_nombre in features:
                    muestra_baja.append(features[high_nombre])
                else:
                    muestra_baja.append(valor * 1.5)
            elif 'ratio' in nombre:
                muestra_baja.append(1 / (valor + 1e-8))
            elif 'diff' in nombre:
                muestra_baja.append(-valor)
            else:
                muestra_baja.append(valor)
        
        # Crear dataset
        samples = [muestra_alta, muestra_baja]
        labels = [1, 0]
        
        # Agregar muestras con variabilidad controlada
        for i in range(n_samples):
            # Variabilidad seg√∫n complejidad
            variabilidad = 0.1 if separabilidad == 'muy_alta' else 0.15
            
            noise_alta = [val * np.random.normal(1.0, variabilidad) for val in muestra_alta]
            samples.append(noise_alta)
            labels.append(1)
            
            noise_baja = [val * np.random.normal(1.0, variabilidad) for val in muestra_baja]
            samples.append(noise_baja)
            labels.append(0)
        
        feature_names = list(features.keys())
        df = pd.DataFrame(samples, columns=feature_names)
        df['label'] = labels
        
        return df
    
    def entrenar_modelo_quimico_especifico(self, X, y, feature_names, tipo_modelo, contaminante, perfil):
        """
        Entrena modelo espec√≠fico con consideraciones qu√≠micas
        """
        try:
            # Escalado
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # Divisi√≥n seg√∫n tama√±o
            if len(X) >= 4:
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=0.3, random_state=42, stratify=y
                )
            else:
                X_train = X_test = X_scaled
                y_train = y_test = y
            
            # Crear modelo seg√∫n tipo y perfil qu√≠mico
            modelo = self._crear_modelo_adaptado(tipo_modelo, perfil)
            
            # Entrenar
            modelo.fit(X_train, y_train)
            
            # Evaluar
            y_train_pred = modelo.predict(X_train)
            y_test_pred = modelo.predict(X_test)
            
            train_f1 = f1_score(y_train, y_train_pred, zero_division=0)
            test_f1 = f1_score(y_test, y_test_pred, zero_division=0)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            # AUC
            try:
                if hasattr(modelo, 'predict_proba'):
                    y_proba = modelo.predict_proba(X_test)[:, 1]
                    if len(set(y_test)) > 1:
                        auc = roc_auc_score(y_test, y_proba)
                    else:
                        auc = 0.5
                else:
                    auc = 0.5
            except:
                auc = 0.5
            
            # Feature importance
            feature_importance = {}
            if hasattr(modelo, 'feature_importances_'):
                for i, imp in enumerate(modelo.feature_importances_):
                    if i < len(feature_names):
                        feature_importance[feature_names[i]] = float(imp)
            elif hasattr(modelo, 'coef_'):
                coef = modelo.coef_[0] if len(modelo.coef_.shape) > 1 else modelo.coef_
                for i, imp in enumerate(np.abs(coef)):
                    if i < len(feature_names):
                        feature_importance[feature_names[i]] = float(imp)
            
            resultado = {
                'tipo_modelo': tipo_modelo,
                'test_f1': float(test_f1),
                'test_accuracy': float(test_acc),
                'train_f1': float(train_f1),
                'gap_f1': float(train_f1 - test_f1),
                'auc': float(auc),
                'feature_importance': feature_importance,
                'exito': True
            }
            
            print(f"   ‚úÖ {tipo_modelo}: F1={test_f1:.3f}, Gap={train_f1-test_f1:+.3f}")
            
            return resultado
            
        except Exception as e:
            print(f"   ‚ùå {tipo_modelo}: Error - {str(e)}")
            return {'tipo_modelo': tipo_modelo, 'test_f1': 0.0, 'exito': False}
    
    def _crear_modelo_adaptado(self, tipo_modelo, perfil):
        """Crea modelo adaptado seg√∫n tipo y perfil qu√≠mico"""
        
        if tipo_modelo == 'logistic_regression':
            # Para iones simples, regularizaci√≥n suave
            C = 1.0 if perfil['tipo'] == 'inorganico' else 0.1
            return LogisticRegression(random_state=42, max_iter=1000, C=C)
            
        elif tipo_modelo == 'svm_linear':
            C = 1.0 if perfil.get('separabilidad_esperada') == 'alta' else 0.1
            return SVC(kernel='linear', random_state=42, C=C, probability=True)
            
        elif tipo_modelo == 'svm_rbf':
            return SVC(kernel='rbf', random_state=42, C=1.0, gamma='scale', probability=True)
            
        elif tipo_modelo == 'random_forest':
            # Par√°metros seg√∫n complejidad qu√≠mica
            n_trees = 20 if perfil.get('complejidad_esperada') == 'alta' else 10
            max_depth = 4 if perfil.get('complejidad_esperada') == 'alta' else 3
            
            return RandomForestClassifier(
                n_estimators=n_trees, max_depth=max_depth, random_state=42,
                min_samples_split=2, min_samples_leaf=1
            )
            
        elif tipo_modelo == 'xgboost_conservador':
            return xgb.XGBClassifier(
                n_estimators=5, max_depth=2, learning_rate=0.1,
                reg_alpha=1.0, reg_lambda=2.0, random_state=42, verbosity=0
            )
            
        elif tipo_modelo == 'xgboost_completo':
            return xgb.XGBClassifier(
                n_estimators=20, max_depth=4, learning_rate=0.05,
                reg_alpha=0.5, reg_lambda=1.0, random_state=42, verbosity=0
            )
    
    def determinar_categoria_dataset(self, n_muestras):
        """Determina categor√≠a del dataset"""
        if n_muestras <= 4:
            return 'extremo'
        elif n_muestras <= 10:
            return 'pequeno'
        elif n_muestras <= 30:
            return 'mediano'
        else:
            return 'grande'
    
    def cargar_datos_crudos(self, contaminante):
        """Carga datos crudos (l√≥gica exitosa probada)"""
        carpeta = self.mapeo_carpetas[contaminante]
        ruta_carpeta = os.path.join(self.directorio_base, carpeta)
        
        archivos_espectrales = [f for f in os.listdir(ruta_carpeta) 
                              if f.endswith('_datos_espectrales.csv')]
        archivo_espectral = archivos_espectrales[0]
        ruta_archivo = os.path.join(ruta_carpeta, archivo_espectral)
        
        datos = pd.read_csv(ruta_archivo)
        return datos.dropna().sort_values('wavelength').reset_index(drop=True)
    
    def _mostrar_resultados_completos(self, resultado):
        """Muestra resultados del sistema completo"""
        
        print(f"\n{'='*70}")
        print(f"üß¨ RESULTADOS SISTEMA QU√çMICO-H√çBRIDO COMPLETO")
        print(f"{'='*70}")
        
        perfil = resultado['perfil_quimico']
        
        print(f"üìã Contaminante: {resultado['contaminante']}")
        print(f"üè∑Ô∏è Tipo qu√≠mico: {perfil['tipo']} - {perfil['subtipo']}")
        print(f"üìä Categor√≠a dataset: {resultado['categoria_dataset']} ({resultado['n_muestras_total']} muestras)")
        print(f"üîß Modelo final: {resultado['modelo_usado']}")
        print(f"üß™ Modelos probados: {resultado['modelos_probados']}")
        
        print(f"\nüìä M√âTRICAS FINALES:")
        print(f"   üéØ Test F1:       {resultado['test_f1']:.4f}")
        print(f"   üéØ Test Accuracy: {resultado['test_accuracy']:.4f}")
        print(f"   üéØ AUC:           {resultado['auc']:.4f}")
        print(f"   üìä Gap F1:        {resultado['gap_f1']:+.4f}")
        
        # Evaluaci√≥n contextualizada
        f1 = resultado['test_f1']
        separabilidad = perfil.get('separabilidad_esperada', 'media')
        
        if separabilidad == 'muy_alta' and f1 >= 0.9:
            evaluacion = "üü¢ PERFECTO (esperado para alta separabilidad)"
        elif separabilidad == 'alta' and f1 >= 0.8:
            evaluacion = "üü¢ EXCELENTE"
        elif separabilidad == 'media' and f1 >= 0.6:
            evaluacion = "üü° BUENO (esperado para separabilidad media)"
        elif f1 >= 0.4:
            evaluacion = "üü† MODERADO"
        else:
            evaluacion = "üî¥ REQUIERE OPTIMIZACI√ìN"
        
        print(f"   üèÜ Evaluaci√≥n: {evaluacion}")
        
        if resultado['feature_importance']:
            print(f"\nüîë TOP FEATURES QU√çMICAMENTE RELEVANTES:")
            top_features = sorted(resultado['feature_importance'].items(), 
                                key=lambda x: x[1], reverse=True)[:5]
            for i, (feature, importance) in enumerate(top_features, 1):
                print(f"   {i}. {feature}: {importance:.4f}")
        
        print(f"\n‚è±Ô∏è Tiempo total: {resultado['tiempo_entrenamiento']:.1f}s")
    
    def _guardar_resultados_completos(self, contaminante, resultado):
        """Guarda resultados completos"""
        try:
            dir_contaminante = os.path.join(self.results_dir, contaminante)
            os.makedirs(dir_contaminante, exist_ok=True)
            
            ruta_json = os.path.join(dir_contaminante, f"{contaminante}_completo.json")
            
            with open(ruta_json, 'w', encoding='utf-8') as f:
                json.dump(resultado, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"   üíæ Resultados guardados: {ruta_json}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error guardando: {e}")

def probar_sistema_completo():
    """Prueba el sistema completo qu√≠mico-h√≠brido"""
    
    print("üß¨ SISTEMA COMPLETO: QU√çMICO + H√çBRIDO")
    print("="*50)
    print("üéØ Adaptaci√≥n qu√≠mica espec√≠fica + Selecci√≥n h√≠brida de modelos")
    print()
    
    sistema = SistemaCompletoQuimicoHibrido("todo/firmas_espectrales_csv")
    
    # Contaminantes de diferentes tipos qu√≠micos
    contaminantes_test = [
        'Nh4_Mg_L', 'Po4_Mg_L', 'So4_Mg_L',           # Inorg√°nicos
        'Caffeine_Ng_L', 'Acesulfame_Ng_L',            # Org√°nicos
        'Candesartan_Ng_L', 'Diclofenac_Ng_L',         # Farmac√©uticos
        'Turbidity_Ntu', 'Doc_Mg_L'                   # F√≠sico-qu√≠micos
    ]
    
    resultados = {}
    
    for i, contaminante in enumerate(contaminantes_test, 1):
        print(f"\n[{i}/3] üî¨ PROCESANDO: {contaminante}")
        
        resultado = sistema.entrenar_contaminante_completo(contaminante)
        
        if resultado:
            resultados[contaminante] = resultado
    
    # An√°lisis final
    print(f"\n{'='*70}")
    print(f"üìä AN√ÅLISIS FINAL SISTEMA COMPLETO")
    print(f"{'='*70}")
    
    if resultados:
        print(f"‚úÖ Resultados exitosos: {len(resultados)}/3")
        print()
        print(f"{'Contaminante':<15} | {'Tipo':<12} | {'F1':<6} | {'Modelo':<12} | {'Estado'}")
        print("-" * 70)
        
        for cont, res in resultados.items():
            tipo = res['perfil_quimico']['tipo'][:10]
            f1 = res['test_f1']
            modelo = res['modelo_usado'][:10]
            
            if f1 >= 0.8:
                estado = "üü¢ EXCELENTE"
            elif f1 >= 0.6:
                estado = "üü° BUENO"  
            elif f1 >= 0.4:
                estado = "üü† MODERADO"
            else:
                estado = "üî¥ MEJORABLE"
            
            print(f"{cont:<15} | {tipo:<12} | {f1:<6.3f} | {modelo:<12} | {estado}")
        
        # Conclusiones
        f1_promedio = np.mean([r['test_f1'] for r in resultados.values()])
        print(f"\nüìä F1 Score promedio: {f1_promedio:.3f}")
        
        exitos = sum(1 for r in resultados.values() if r['test_f1'] >= 0.6)
        print(f"üéØ Casos exitosos (F1‚â•0.6): {exitos}/3")
        
        if exitos == 3:
            print(f"\nüéâ SISTEMA COMPLETO TOTALMENTE EXITOSO!")
            print(f"   ‚úÖ Adaptaci√≥n qu√≠mica espec√≠fica funcional")
            print(f"   ‚úÖ Selecci√≥n h√≠brida de modelos efectiva")
            print(f"   ‚úÖ Listo para expansi√≥n a todos los contaminantes")
        elif exitos >= 2:
            print(f"\nüíõ SISTEMA COMPLETO MAYORMENTE EXITOSO")
            print(f"   ‚úÖ Funcionamiento robusto demostrado")
            print(f"   üîß Refinamiento menor necesario")
        else:
            print(f"\nüîß SISTEMA COMPLETO REQUIERE OPTIMIZACI√ìN")
            print(f"   ‚ö†Ô∏è Revisar perfiles qu√≠micos espec√≠ficos")
    
    return resultados

if __name__ == "__main__":
    import numpy as np
    probar_sistema_completo()